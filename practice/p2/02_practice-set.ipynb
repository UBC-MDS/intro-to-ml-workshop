{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "# All options https://otter-grader.readthedocs.io/en/latest/otter_assign/v1/notebook_format.html#assignment-metadata\n",
    "environment: environment.yml\n",
    "overwrite_requirements: true\n",
    "export_cell: false\n",
    "check_all_cell: false\n",
    "show_question_points: true\n",
    "# All generate options https://otter-grader.readthedocs.io/en/latest/workflow/otter_generate/index.html#grading-configurations\n",
    "generate:\n",
    "    show_hidden: true\n",
    "    show_stdout: true\n",
    "files:\n",
    "    - data\n",
    "    - img\n",
    "    - .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice set 2: Preprocessing with `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3247a4b883a670c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. This homework will give you some practice of data preprocessing and building a supervised machine learning pipeline on a medium-sized dataset which has different types of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Dataset and preliminary EDA\n",
    "<hr>\n",
    "\n",
    "In this lab, you will be working on [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). Download the CSV and save it as `adult.csv` under the data folder in the current folder. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. Go through the information on [the dataset and features](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The starter code below loads the data CSV (assuming that it is saved as `adult.csv` under the data folder). \n",
    "\n",
    "_Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "census_df = pd.read_csv(\"data/adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1.1\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data splitting \n",
    "rubric={autograde}\n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into `train_df` (40%) and `test_df` (60%) with `random_state = 123`. Keep the target column (`income`) in the splits so that we can use it in the exploratory data analysis.  \n",
    "\n",
    "_Usually, having more data for training is a good idea. But here I'm using 40%/60% split because running cross-validation with this dataset can take a long time on a modest laptop. A smaller training data means it will be a bit faster to train the model on your laptop. A side advantage of this is that with a bigger test split, we'll have a more reliable estimate of the model performance!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "train_df, test_df = train_test_split(census_df, test_size=0.6, random_state=123)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not train_df is None and not test_df is None, \"Please use the provided variables.\"\n",
    "assert train_df.shape == (13024, 15), \"The dimensions of the training set are incorrect\"\n",
    "assert test_df.shape == (19537, 15), \"The dimensions of the test set are incorrect\"\n",
    "assert train_df.loc[12846][['age', 'education', 'occupation', 'capital.loss']].tolist() == [49, 'Some-college', 'Craft-repair', 0], \"Are you using the provided random state?\"\n",
    "assert not 20713 in train_df.index, 'Are you using the provided random state?' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Probably these were the questions not answered by some people during the census.  Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values because they are encoded as strings instead of an actual NaN in Python. So let's replace them with `np.nan` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.replace(\"?\", np.nan)\n",
    "test_df = test_df.replace(\"?\", np.nan)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"?\" symbols are now replaced with NaN values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1.2\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1    \n",
    "    - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 `describe()` method\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the output of `train_df.describe()` with `include='all'` argument and store it in a variable called `census_summary`.\n",
    "2. What are the highest hours per week someone reported? Store it in a variable called `max_hours_per_week`.\n",
    "3. What is the most frequently occurring occupation in this dataset? Store it in a variable called `most_freq_occupation`.\n",
    "4. Store the column names of the columns with missing values as a list in a variable called `missing_vals_cols`. \n",
    "5. Store the column names of all numeric-looking columns, irrespective of whether you want to include them in your model or not, as a list in a variable called `numeric_cols`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_summary = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "census_summary = train_df.describe(include=\"all\")\n",
    "census_summary\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hours_per_week = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "max_hours_per_week = census_summary.loc['max']['hours.per.week']\n",
    "max_hours_per_week\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_occupation = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "most_freq_occupation = census_summary.loc['top']['occupation']\n",
    "most_freq_occupation\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "train_df.info()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "missing_vals_cols = None\n",
    "numeric_cols = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "missing_vals_cols = ['workclass', 'occupation', 'native.country']\n",
    "numeric_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the lists for the autograder\n",
    "missing_vals_cols.sort()\n",
    "numeric_cols.sort()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "assert isinstance(census_summary, pd.DataFrame), \"census_summary dataftame is not created\"\n",
    "assert census_summary.shape == (11, 15), \"census_summary shape is incorrect. Probably you are not including all columns\"\n",
    "assert census_summary.loc['min']['age'] == 17.0, \"census_summary dataframe is incorrect\"\n",
    "assert census_summary.loc['top']['occupation'] == \"Prof-specialty\", \"census_summary dataframe is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "assert (sha1(str(max_hours_per_week).encode('utf8')).hexdigest() == \"3359de52c8ae993fe0f8fe9c5168a0065bd3c7a4\"), \"max_hours_per_week are incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "assert (sha1(str(most_freq_occupation).encode('utf8')).hexdigest() == \"97165f50eddb0d28a382b0366274e2fe38505644\"), \"most_freq_occupation is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "assert (sha1(str(missing_vals_cols).encode('utf8')).hexdigest() == \"6bc5e13d4d66b306e52701ee9a1e5e21bf19aeb0\"), \"Please use the exact column/feature name. Also, make sure the lists are sorted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5\n",
    "assert (sha1(str(numeric_cols).encode('utf8')).hexdigest() == \"615afaf5011128d641ab8a73289d57bd01a3ec37\"), \"Please use the exact column/feature name. Also, make sure the lists are sorted.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1.3\n",
    "points: 5\n",
    "manual: True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Visualizing features\n",
    "rubric={point}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each numeric feature in `numeric_cols` you identified above, visualize the histograms for <=50K and >50K classes. \n",
    "2. Write a sentence or two describing your observations. \n",
    "\n",
    "> You can use the library of your choice for visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## IGNORE ## \n",
    "# BEGIN SOLUTION\n",
    "for feat in numeric_cols:\n",
    "    ax = train_df.groupby(\"income\")[feat].plot.hist(bins=40, alpha=0.4, legend=True, density=True)\n",
    "    plt.xlabel(feat)\n",
    "    plt.title(\"Histogram of \" + feat)\n",
    "    plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary observations**: \n",
    "From the density histograms above it seems like middle age, higher capital.gain, higher capital.loss, higher education.num and more work hours.per.week are associated with higher income (>50K income). "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2: Identifying different feature types and transformations  \n",
    "<hr>\n",
    "\n",
    "Usually, data comes in a format which is not directly passed to machine learning models. A machine learning practitioner needs to examine each column carefully and come up with a way to effectively encode the information given in each column. Let's identify what kind of features do we have and consider some reasonable ways to encode them.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2.1\n",
    "points: 13\n",
    "manual: True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Identify transformations to apply\n",
    "rubric={points}\n",
    "\n",
    "Below we are providing possible transformations which can be applied on each column in `census_df`.  \n",
    "\n",
    "**Your tasks:**\n",
    "1. Write your justification or explanation for each row in the _Explanation_ column. An example explanation is given for the `age` feature. \n",
    "\n",
    "> You can find the information about the columns [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "> This question is a bit open-ended. If you do not agree with the provided transformation, feel free to argue your case in the explanation. That said, for the autograder to work in the rest of the assignment, go with the transformations provided below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation | Explanation\n",
    "| --- | ----------- | ----- |\n",
    "| age | scaling |  A numeric feature with no missing values. It will be a good idea to apply scaling, as the range of values (17 to 90) is quite different compared to other numeric features.|\n",
    "| workclass | imputation, one-hot encoding | |\n",
    "| fnlwgt | drop |  |\n",
    "| education | ordinal encoding | |\n",
    "| education.num | drop | |\n",
    "| marital.status | one-hot encoding  | |\n",
    "| occupation | imputation, one-hot encoding  | |\n",
    "| relationship | one-hot encoding  | |\n",
    "| race | drop  |  |\n",
    "| sex | one-hot encoding with \"binary=True\" | |\n",
    "| capital.gain | scaling |  | \n",
    "| capital.loss | scaling |  |\n",
    "| hours.per.week | scaling | |\n",
    "| native.country | imputation, one-hot encoding | | \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation | Explanation\n",
    "| --- | ----------- | ----- |\n",
    "| age | scaling |  numeric variable in the range 17 to 90. No missing values.|\n",
    "| workclass | imputation, one-hot encoding | categorical variable with XX categories, some missing values|\n",
    "| fnlwgt | drop | The column represents the weight assigned by the US census bureau to each row. This is not really a feature which is relevant to predict the income |\n",
    "| education | ordinal encoding | The column has a number of education levels which have some ordering associated with them. For example, \"Bachelors\" < \"Masters\"|\n",
    "| education.num | drop | duplicate column |\n",
    "| marital.status | one-hot encoding  | Categorical column with no missing values |\n",
    "| occupation | imputation, one-hot encoding  | Categorical column with missing values |\n",
    "| relationship | one-hot encoding  | Categorical column with no missing values |\n",
    "| race | drop  | Categorical column with no missing values. It might not be a good idea to include the race feature to predict income. Such systems get used in applications which can affect real people. For example, this prediction might be used in deciding whether to approve a loan application or not. Influencing this decision by race feature might harm people belonging to certain race.   |\n",
    "| sex | one-hot encoding with \"binary=True\" | Although sex in general is not binary, in this dataset, there are only two possible values for this feature and that's why we are treating it as a binary feature and applying one-hot encoding with \"binary=True\". So only one column will be created for the feature. |\n",
    "| capital.gain | scaling | numeric feature with no missing values | \n",
    "| capital.loss | scaling | numeric feature with no missing values |\n",
    "| hours.per.week | scaling | numeric feature with no missing values |\n",
    "| native.country | imputation, one-hot encoding | categorical feature with missing values.| "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2.2\n",
    "points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Identify feature types \n",
    "rubric={autograde}\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "1. Based on the types of transformations we want to apply on the features above, identify different feature types and store them in the variables below as lists.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lists below.\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "ordinal_features = []\n",
    "binary_features = []\n",
    "drop_features = []\n",
    "target = \"income\"\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "numeric_features = [\"capital.gain\", \"age\", \"capital.loss\",\"hours.per.week\"]\n",
    "categorical_features = [\"marital.status\", \"native.country\", \"relationship\", \"occupation\", \"workclass\"]\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\"sex\"]\n",
    "drop_features = [\"fnlwgt\", \"race\", \"education.num\"]\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting all the lists above for the autograder\n",
    "numeric_features.sort()\n",
    "categorical_features.sort()\n",
    "ordinal_features.sort()\n",
    "binary_features.sort()\n",
    "drop_features.sort()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (sha1(str(numeric_features).encode('utf8')).hexdigest() == \"71401cf60034fd69eee7398866359f612adf3e15\"), \"numeric_features list is not correct\"\n",
    "assert (sha1(str(categorical_features).encode('utf8')).hexdigest() == \"af1a4022c0362405678be5c3a6735578a8c0069f\"), \"categorical_features list is not correct\"\n",
    "assert (sha1(str(ordinal_features).encode('utf8')).hexdigest() == \"95b86602c44211f3ad662bb58b8e53d024106d05\"), \"ordinal_features list is not correct\"\n",
    "assert (sha1(str(binary_features).encode('utf8')).hexdigest() == \"d4b7aa4c56ac2f98e6ac9cec7768484b415b7337\"), \"binary_features list is not correct\"\n",
    "assert (sha1(str(drop_features).encode('utf8')).hexdigest() == \"62aab57d42c54be3dfd3c55020e5a167ca1a84c3\"), \"drop_features list is not correct\"\n",
    "assert (sha1(str(target).encode('utf8')).hexdigest() == \"0f613350b66e64d92ef21bc4dcdbf8996cb4edf0\"), \"target variable is not set correctly\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Baseline models "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3.1\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Separating feature vectors and targets  \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create `X_train`, `y_train`, `X_test`, `y_test` from `train_df` and `test_df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "X_train = train_df.drop(columns=[target])\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_test = test_df.drop(columns=[target])\n",
    "y_test = test_df[target]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not X_train is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n",
    "assert not y_train is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n",
    "assert not X_test is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n",
    "assert not y_test is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n",
    "assert X_train.shape == (13024, 14), \"The dimensions of X_train are incorrect\"\n",
    "assert y_train.shape == (13024, ), \"The dimensions of y_train are incorrect. Are you splitting correctly\"\n",
    "assert X_test.shape == (19537,14), \"The dimensions of X_test are incorrect. Are you splitting correctly? Are you using single brackets?\"\n",
    "assert y_test.shape == (19537,), \"The dimensions of y_test are incorrect. Are you splitting correctly? Are you using single brackets?\"\n",
    "assert 'income' not in list(X_train.columns), \"Make sure the target variable is not part of your X dataset.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3.2\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dummy classifier\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out 5-fold cross-validation using `scikit-learn`'s `cross_validate` function with `return_train_scores=True` and store the results as a dataframe named `dummy_df` where each row corresponds to the results from a cross-validation fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = None \n",
    "\n",
    "# BEGIN SOLUTION\n",
    "dummy = DummyClassifier()\n",
    "scores = cross_validate(dummy, X_train, y_train, return_train_score=True)\n",
    "dummy_df = pd.DataFrame(scores)\n",
    "dummy_df\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not dummy_df is None, \"Have you used the correct variable to store the results?\"\n",
    "assert sorted(list(dummy_df.columns)) == ['fit_time','score_time','test_score','train_score'], \"Your solution contains incorrect columns.\"\n",
    "assert dummy_df.shape == (5,4), \"Are you carrying out 5-fold cross-validation and are you passing return_train_score=True?\"\n",
    "assert np.isclose(round(dummy_df['test_score'].mean(),3), 0.758), \"The test scores seem wrong. Are you calling the cross_validate correctly?\"\n",
    "assert np.isclose(round(dummy_df['train_score'].mean(),3), 0.758), \"The train scores seem wrong. Are you calling the cross_validate correctly?\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3.3\n",
    "points: 2\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Discussion\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Hopefully, you were able to run cross-validation with dummy classifier successfully in the question above. At this point, if you train [`sklearn`'s `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on `X_train` and `y_train` would it work? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It won't work at this point because our data is not preprocessed yet; we have some categorical columns and some NaN values in numeric columns. We need to preprocess it first before feeding it into ML algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Column transformer \n",
    "<hr>\n",
    "\n",
    "In this dataset, we have different types of features: numeric features, an ordinal feature, categorical features, and a binary feature. We want to apply different transformations on different columns and therefore we need a column transformer. First, we'll define different transformations on different types of features and then will create a `scikit-learn`'s `ColumnTransformer` using `make_column_transformer`. For example, the code below creates a `numeric_transformer` for numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercises below, you'll create transformers for other types of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4.1\n",
    "points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preprocessing ordinal features\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a transformer called `ordinal_transformer` for our ordinal features. \n",
    "\n",
    "> Ordering of some of the education levels is not obvious. Assume that \"HS-grad\" < \"Prof-school\" < \"Assoc-voc\" < \"Assoc-acdm\" < \"Some-college\" < \"Bachelors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_transformer = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "train_df[\"education\"].unique()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]\n",
    "assert set(education_levels) == set(train_df[\"education\"].unique())\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "ordinal_transformer = OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not ordinal_transformer is None, \"Are you using the correct variable name?\"\n",
    "assert type(ordinal_transformer.get_params()['categories'][0]) is list, \"Are you passing education levels as a list of lists?\"\n",
    "assert ordinal_transformer.get_params()['dtype'] == int, \"Please set the dtype to int\"\n",
    "assert (sha1(str(ordinal_transformer.get_params()['categories'][0]).encode('utf8')).hexdigest() == \"893a03d114b2af09b53247866c6eea54ebfd090f\") or (sha1(str(ordinal_transformer.get_params()['categories'][0]).encode('utf8')).hexdigest() == \"81059b8bebc9ddb03d61bf07cfd9b9b6b0da288e\"), \"Make sure you are passing categories sorted on levels of education. (Ascending or descending shouldn't matter.)\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4.2\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Preprocessing binary features\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a transformer called `binary_transformer` for our binary features.\n",
    "\n",
    "> _Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = None\n",
    "# BEGIN SOLUTION\n",
    "binary_transformer = OneHotEncoder(drop=\"if_binary\", dtype=int)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not binary_transformer is None, \"Are you using the correct variable name?\"\n",
    "assert binary_transformer.get_params()['drop'] == 'if_binary', \"Are you passing `drop=if_binary`?\"\n",
    "assert binary_transformer.get_params()['dtype'] == int, \"Please set the dtype to int\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4.3\n",
    "points: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Preprocessing categorical features\n",
    "rubric={autograde}\n",
    "\n",
    "In Exercise 2.3, we saw that there are 3 categorical features with missing values. So first we need to impute the missing values and then encode these features with one-hot encoding. For the purpose of this assignment, let's just have imputation as the first step for all categorical features even when they do not have missing values. This should be OK because if a feature doesn't have any missing value,  imputation won't be applied. \n",
    "\n",
    "If we want to apply more than one transformation on a set of features, we need to create a [`scikit-learn` `Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). For example, for categorical features we can create a `scikit-learn` `Pipeline` with first step as imputation and the second step as one-hot encoding. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `sklearn` `Pipeline` using [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) called `categorical_transformer` for our categorical features with two steps: `SimpleImputer` for imputation with `strategy=\"constant\"` and `fill_value=\"missing\"` and `OneHotEncoder` with `handle_unknown=\"ignore\"` and `sparse=False` for one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not categorical_transformer is None, \"Are you using the correct variable name?\"\n",
    "assert type(categorical_transformer) is Pipeline, \"Are you creating a scikit-learn Pipeline?\"\n",
    "assert len(categorical_transformer.get_params()['steps']) == 2, \"Are you creating a pipeline with two steps?\"\n",
    "assert categorical_transformer.get_params()['simpleimputer__strategy'] == 'constant', \"Are you passing strategy=constant in the SimpleImputer?\"\n",
    "assert categorical_transformer.get_params()['simpleimputer__fill_value'] == 'missing', \"Are you passing fill_value='missing' in the SimpleImputer?\"\n",
    "assert categorical_transformer.get_params()['onehotencoder__handle_unknown'] == 'ignore', \"Are you passing handle_unknown = 'ignore' argument to your OHE?\"\n",
    "assert categorical_transformer.get_params()['onehotencoder__sparse'] == False, \"Are you creating a sparase matrix for OHE?\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4.4\n",
    "points: \n",
    "      - 5\n",
    "      - 1\n",
    "      - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Creating a column transformer. \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Create a `sklearn` `ColumnTransformer` named `preprocessor` using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) with the transformers defined in the previous exercises. Use the sequence below in the column transformer and add a \"drop\" step for the `drop_features` in the end.  \n",
    "    - `numeric_transformer`\n",
    "    - `ordinal_transformer`\n",
    "    - `binary_transformer`\n",
    "    - `categorical_transformer`\n",
    "2. Transform the data by calling `fit_transform` on the training set and save it as a dataframe in a variable called `transformed_df`. How many new columns have been created in the preprocessed data in comparison to the original `X_train`? Store the difference between the number of columns in `transformed_df` and `X_train` in a variable called `n_new_cols`. \n",
    "\n",
    "> You are not required to do this but optionally you can try to get column names of the transformed data and create the dataframe `transformed_df` with proper column names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),    \n",
    "    (binary_transformer, binary_features),    \n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = None\n",
    "n_new_cols = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "data = preprocessor.fit_transform(X_train)\n",
    "ohe_feats = preprocessor.named_transformers_['pipeline'].named_steps['onehotencoder'].get_feature_names_out(categorical_features).tolist()\n",
    "feature_names = numeric_features + ordinal_features + binary_features + ohe_feats\n",
    "transformed_df = pd.DataFrame(data, columns=feature_names)\n",
    "n_new_cols = transformed_df.shape[1] - X_train.shape[1]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1\n",
    "assert not preprocessor is None, \"Are you using the correct variable name?\"\n",
    "assert len(preprocessor.get_params()['transformers']) in range(4,6,1), \"Have you included all the transformers?\"\n",
    "assert 'onehotencoder' in preprocessor.get_params().keys(), 'Either the categorical_transformer or binary_transformer is not included.'\n",
    "assert 'standardscaler' in preprocessor.get_params().keys(), 'numeric_transformer is not included.'\n",
    "assert 'ordinalencoder' in preprocessor.get_params().keys(), 'ordinal_transformer is not included.'\n",
    "assert 'drop' in preprocessor.get_params().keys(), 'drop features step is not included.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2\n",
    "assert not transformed_df is None, \"Are you using the correct variable name?\"\n",
    "assert sha1(str(transformed_df.shape).encode('utf8')).hexdigest() == 'a0521f0cdbcd77cd213e7d1a3cfc13c1c7c92a6e', \"The shape of the transformed data is incorrect.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sha1(str(n_new_cols).encode('utf8')).hexdigest() == 'b7103ca278a75cad8f7d065acda0c2e80da0b7dc', \"The number of new columns (n_new_cols) is incorrect.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION \n",
    "name: q4.5\n",
    "points: 8\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.5 Short answer questions\n",
    "rubric={reasoning:8}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Answer each of the following questions in 2 to 3 sentences. \n",
    "\n",
    "1. What is the problem with calling `fit_transform` on your test data with `StandardScaler`?\n",
    "2. Why is it important to follow the Golden Rule? If you violate it, will that give you a worse classifier?\n",
    "3. What are two advantages of using sklearn Pipelines? \n",
    "4. When is it appropriate to use sklearn `ColumnTransformer`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You need to perform the same transformations on the train and test data, otherwise the results will not make sense.\n",
    "2. Not necessarily a worse classifier, but you'll get an overly optimistic estimate of your model performance when you compute test accuracy which is bad.\n",
    "3. (1) prevents violating the Golden Rule, (2) helps keep track of all your transformations in one place.\n",
    "4. When we have different types of features and we want to apply different transformations on different features. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Building models \n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. Below, I'm providing the function we used in class which returns mean cross-validation score along with standard deviation for a given model. Use it to keep track of your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {}  # dictionary to store all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I'm showing an example where I call `mean_std_cross_val_scores` with `DummyClassifier`. The function calls `cross_validate` with the passed arguments and returns a series with mean cross-validation results and std of cross-validation. When you train new models, you can just add the results of these models in `results_dict`, which can be easily converted to a dataframe so that you can have a table with all your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(random_state = 123)\n",
    "pipe = make_pipeline(preprocessor, dummy)\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    pipe, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5.1\n",
    "points: 10\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1 Trying different classifiers\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each of the models in the starter code below: \n",
    "    - Define a pipeline with two steps: `preprocessor` from 4.4 and the model as your classifier. \n",
    "    - Carry out 5-fold cross-validation with the pipeline and get the mean cross-validation scores with std by calling the `mean_std_cross_val_scores` function above. \n",
    "    - Store the results in a dataframe called `income_pred_results_df` with the model names in the `models` dictionary below as the index and each row representing results returned by `mean_std_cross_val_scores` function above. In other words, `income_pred_results_df` should look similar to the `results_df` dataframe above with more rows for the models below. \n",
    "    \n",
    "> This might take a while to run. Be patient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(random_state=123),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(random_state=123),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_pred_results_df = None \n",
    "# BEGIN SOLUTION\n",
    "for model_name, model in models.items():\n",
    "    # print(model_name, \":\")\n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    results_dict[model_name] = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, cv=5, return_train_score=True\n",
    "    )\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IGNORE ##\n",
    "# BEGIN SOLUTION\n",
    "income_pred_results_df = pd.DataFrame(results_dict).T\n",
    "income_pred_results_df\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5.2\n",
    "points: 5\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2 Discussion \n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the train and validation accuracies and `fit` and `score` times for all the models in the results above. How do the validation accuracies compare to the `DummyClassifier` model? Which model has the best validation accuracy? Which model has the fastest `fit` time? What about fastest `score` time? Which model is overfitting the most and the least?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Observations\n",
    "\n",
    "- All three models have better cross-validation scores than the dummy classifier. Of course, the dummy classifier is the fastest in fitting and scoring and the most underfit model. But let's focus on other three interesting models in the discussion below.   \n",
    "- SVC has the best cross-validation scores (mean validation score = 0.855), followed by KNN and decision tree.  \n",
    "- As expected, KNN is the fastest model for fitting and decision tree is the fastest model for scoring. SVM seems to be much slower compared to KNN and decision tree but is more accurate. \n",
    "- Decision tree is clearly overfitting the most (mean train score = 0.987, mean validation score = 0.814) and SVM is overfitting the least (mean train score = 0.855, mean validation score = 0.852). The standard deviation between cross-validation scores is also smaller for SVM RBF compared to KNN and decision tree. So SVM RBF is giving us the best cross-validation scores, it's not overfitting much, it's not sensitive to the training data it's trained on, and it's likely to generalize well on unseen data. That said it's slower compared to the other two models. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5.3\n",
    "points: 10\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter optimization\n",
    "rubric={points}\n",
    "\n",
    "In this exercise, you'll carry out hyperparameter optimization for the hyperparameter `C` of SVC RBF classifier. In practice, you'll carry out hyperparameter optimization for all different hyperparameters of the most promising classifiers. For the purpose of this assignment, we'll only do it for the `SVC` classifier with one hyperparameter, namely `C`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each `C` value in the `param_grid` below: \n",
    "    - Create a pipeline object with two steps: preprocessor from 4.4 and `SVC` classifier with the `C` value.\n",
    "    - Carry out 5-fold cross validation with the pipeline.  \n",
    "    - Store the results in `results_dict` and display results as a pandas DataFrame. \n",
    "2. Which hyperparameter value seems to be performing the best? In this \n",
    "assignment, consider the hyperparameter value that gives you the highest cross-validation score as the \"best\" one. Store it in a variable called `best_C`. (Since this question is not autograded, please store the value directly as a number, something like `best_C = 0.001`, if `C = 0.001` is giving you the highest CV score.) Is it different than the default value for the hyperparameter used by `scikit-learn`? \n",
    "\n",
    "> Note: Running this will take a while. Please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": np.logspace(-1, 2, 4)}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IGNORE ##\n",
    "# BEGIN SOLUTION\n",
    "for param in param_grid[\"C\"]:\n",
    "    model_name = \"RBF SVC\"\n",
    "    pipe = make_pipeline(preprocessor, SVC(C=param))\n",
    "\n",
    "    key = model_name + \"(C= \" + str(param) + \")\"\n",
    "    results_dict[key] = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, cv=5, return_train_score=True\n",
    "    )\n",
    "# END SOLUTION    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IGNORE ##\n",
    "# BEGIN SOLUTION\n",
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df\n",
    "# END SOLUTION    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "# best_C_index = results_df.index.values[np.argmax(results_df[\"test_score\"])]\n",
    "best_C = 100.0\n",
    "best_C\n",
    "# END SOLUTION    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter C = 100.0 is giving the best results, which is better than the default value for the hyperparameter in `scikit-learn`. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise 6: Evaluating on the test set \n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. In this exercise, you'll examine whether the results you obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q6.1\n",
    "points: 4\n",
    "manual: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Scoring on the unseen test set \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a pipeline named `final_pipeline` with the preprocessor from 4.4 as the first step and the best performing SVC model from 5.4 as the second step. \n",
    "2. Train the pipeline on the entire training set `X_train` and `y_train`. \n",
    "3. Score the pipeline on `X_test` and `y_test` and store the score in a variable called `test_score`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = None\n",
    "test_score = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "final_pipeline = make_pipeline(preprocessor, SVC(C=best_C))\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "test_score = final_pipeline.score(X_test, y_test)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The test results are more or less consistent with the validation results, which is great!! "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Food for thought\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q7.1\n",
    "points: 2\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Challenging) 7.1 The `native.country` column\n",
    "rubric={points}\n",
    "\n",
    "In our column transformer above, we treated `native.country` as a categorical feature, where a new column will be created for each unique category in this column.\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the `value_counts` for this column.\n",
    "2. Point out the problems/limitations associated with the current encoding of this column.   \n",
    "3. Propose and implement a better approach to encode the column. Justify why is your approach better.  \n",
    "4. Examine whether you get better accuracy with your best model when you use this encoding. Discuss your results.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "X_train['native.country'].value_counts()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like most of the values for this column are United States, which makes sense given that the this is United States Census data. There are multiple possible ways to encode this column. Below I'm considering the 15 most frequently occurring countries.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"native.country\"].value_counts()[:15].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "num_most_freq = 15\n",
    "most_frequent = X_train[\"native.country\"].value_counts()[:15].index.tolist()\n",
    "most_frequent\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_q_7_1 = None\n",
    "# BEGIN SOLUTION\n",
    "categorical_native_country = ['native.country']\n",
    "categorical_features_no_country = [\"marital.status\", \"relationship\", \"occupation\", \"workclass\"]\n",
    "\n",
    "categorical_native_country_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", categories= [most_frequent])\n",
    ")\n",
    "\n",
    "preprocessor_q_7_1  = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),    \n",
    "    (binary_transformer, binary_features),    \n",
    "    (categorical_native_country_transformer,categorical_native_country),\n",
    "    (categorical_transformer, categorical_features_no_country),    \n",
    "    (\"drop\", drop_features),\n",
    ")\n",
    "preprocessor_q_7_1.fit(X_train)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_q_7_1  = None\n",
    "n_new_cols_q_7_1  = None\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "data_q_7_1 = preprocessor_q_7_1 .fit_transform(X_train)\n",
    "native_country_feats = preprocessor_q_7_1.named_transformers_['pipeline-1'].named_steps['onehotencoder'].get_feature_names_out(categorical_native_country).tolist()\n",
    "ohe_feats_q_7_1 = preprocessor_q_7_1.named_transformers_['pipeline-2'].named_steps['onehotencoder'].get_feature_names_out(categorical_features_no_country).tolist()\n",
    "feature_names_q_7_1 = numeric_features + ordinal_features + binary_features + native_country_feats + ohe_feats_q_7_1\n",
    "transformed_df_q_7_1 = pd.DataFrame(data_q_7_1, columns=feature_names_q_7_1)\n",
    "n_new_cols_q_7_1 = transformed_df_q_7_1.shape[1] - X_train.shape[1]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "transformed_df_q_7_1\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the preprocessor is working, let's try our best SVC model with this new encoding. It's not necessary that the same hyperparameter will give "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "svc_pipe_q_7_1 = make_pipeline(preprocessor_q_7_1, SVC(C=best_C))\n",
    "results_dict['SVC (C=100.0), most freq 15 countries'] = mean_std_cross_val_scores(\n",
    "    svc_pipe_q_7_1, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "\n",
    "pd.DataFrame(results_dict).T\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we are getting more or less the same cross-validation scores with all countries vs. 15 most frequent countries. The standard deviation is a bit low and a tiny bit less overfitting. So it might be a better idea to go with this simpler model with less number of features.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q7.2\n",
    "points: 3\n",
    "manual: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Challenging) 7.2 Column transformer on Spotify Tracks DB\n",
    "rubric={points}\n",
    "\n",
    "Download [Spotify Tracks DB](https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db) dataset. The features in this dataset are similar to Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset. But the prediction task for this dataset is a regression task of predicting song popularity. See the documentation of spotify-specific features [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different types of features based on what kind of transformations you want to apply on them. Clearly justify your choices. \n",
    "2. Define a column transformer for this data and show the transformed data as a dataframe with appropriate column names.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_df = pd.read_csv(\"data/SpotifyFeatures.csv\")\n",
    "spotify_df.head()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm cleaning up the CSV a bit. In particular, \n",
    "\n",
    "1. I'm changing popularity of 0 to 1 to avoid divide by zero errors latter. Note that the popularity ranges from 0 to 100, with 0 being least popular and 100 being most popular. So changing the popularity from 0 to 1 should not make a huge difference.\n",
    "2. Seems like the genre feature has two slightly different versions of the category Children's Music with two different quotation marks (` and '). I'm mapping them both to \"Children's Music\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_df.loc[spotify_df[\"popularity\"] == 0, \"popularity\"] = 1\n",
    "spotify_df[\"genre\"].value_counts()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_df.loc[spotify_df[\"genre\"] == \"Childrens Music\", \"genre\"] = \"Children's Music\"\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interesting observation: It seems right to collapse these categories into one category but for some reason doing this makes a big difference in R^2 scores. When you skip the step above, i.e., when you keep the two categories separate, I was able to get `Ridge` R^2 score with all features and default alpha value as 0.73. Weird!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is large, which can be computationally intensive. So when we split the data, I am putting most of the data in the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_df.shape\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_train_df, spotify_test_df = train_test_split(spotify_df, test_size=0.97, random_state=123)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_train_df.shape\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_train_df.info()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am defining different feature types and a couple of preprocessors below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "drop_features_spotify = [\"track_id\", \"artist_name\"] # artist name can be a useful feature but most of the values are unique so droping it. Creating groupings of artists might be a good idea.\n",
    "binary_features_spotify = [\"mode\"] # only two possible values\n",
    "categorical_features_spotify = [\"genre\", \"time_signature\", \"key\"] # no particular ordering, apply OHE  \n",
    "text_feature_spotify = \"track_name\" # track name can be a useful feature if people have preferences for songs on specific topic.\n",
    "target_spotify = \"popularity\"\n",
    "numeric_features_spotify = list(\n",
    "    set(spotify_train_df.columns)\n",
    "    - set(drop_features_spotify)\n",
    "    - set([text_feature_spotify])\n",
    "    - set(binary_features_spotify)\n",
    "    - set(categorical_features_spotify)\n",
    "    - set([target_spotify])\n",
    ")\n",
    "assert spotify_train_df.columns.shape[0] == len(\n",
    "    drop_features_spotify\n",
    "    + binary_features_spotify\n",
    "    + categorical_features_spotify\n",
    "    + numeric_features_spotify\n",
    "    + [text_feature_spotify]\n",
    "    + [target_spotify]\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "preprocessor_q_7_2 = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features_spotify),\n",
    "    (OneHotEncoder(drop=\"if_binary\", dtype=\"int\"), binary_features_spotify),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", dtype=\"int\", sparse=False), categorical_features_spotify),\n",
    "    (CountVectorizer(stop_words=\"english\", max_features=100), text_feature_spotify),\n",
    "    (\"drop\", drop_features_spotify),\n",
    ")  # preprocessor which includes all features\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "spotify_X_train, spotify_y_train = spotify_train_df.drop(columns=[target_spotify]), spotify_train_df[target_spotify]\n",
    "spotify_X_test, spotify_y_test = spotify_test_df.drop(columns=[target_spotify]), spotify_test_df[target_spotify]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "transformed_spotify = preprocessor_q_7_2.fit_transform(spotify_X_train)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "ohe_feats_spotify = preprocessor_q_7_2.named_transformers_['onehotencoder-2'].get_feature_names_out(categorical_features_spotify).tolist()\n",
    "text_feats_spotify = preprocessor_q_7_2.named_transformers_['countvectorizer'].get_feature_names_out().tolist()\n",
    "col_names = numeric_features_spotify + binary_features_spotify + ohe_feats_spotify + text_feats_spotify\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "pd.DataFrame(transformed_spotify, columns=col_names)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Seems like the preprocessor is working! "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing the assignment! You are now ready to build a simple supervised machine learning pipeline on real-world datasets! Well done :clap:! \n",
    "\n",
    "![](img/eva-well-done.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
